{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d54ba-bfbf-45bb-8b25-a9d5e3672171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\chabd\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\chabd\\anaconda3\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chabd\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\chabd\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\chabd\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chabd\\anaconda3\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\chabd\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chabd\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.00G/5.00G [41:56<00:00, 1.99MB/s]  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TASK 8: Food Classification (5 Classes) - FULL CODE\n",
    "# Dataset: Food-101\n",
    "# Model: Pretrained ResNet18\n",
    "# Seed: 20240105\n",
    "# ============================================================\n",
    "!pip install torch torchvision matplotlib numpy scikit-learn tqdm pandas\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from PIL import Image\n",
    "\n",
    "# ============================================================\n",
    "# 1. SEED SETUP (REQUIRED)\n",
    "# ============================================================\n",
    "\n",
    "SEED = 20240105\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. README.md CREATION\n",
    "# ============================================================\n",
    "\n",
    "foods = [\"pizza\", \"hamburger\", \"ice_cream\", \"fried_rice\", \"sushi\"]\n",
    "\n",
    "with open(\"README.md\", \"w\") as f:\n",
    "    f.write(\"## TASK 8: Food Classification (5 Classes)\\n\\n\")\n",
    "    f.write(\"### Selected Food Classes:\\n\")\n",
    "    for food in foods:\n",
    "        f.write(f\"- {food}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. DATA PREPROCESSING\n",
    "# ============================================================\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                         (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# 4. LOAD FOOD-101 DATASET\n",
    "# ============================================================\n",
    "\n",
    "dataset = datasets.Food101(\n",
    "    root=\"./data\",\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.Food101(\n",
    "    root=\"./data\",\n",
    "    split=\"test\",\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Map class names to indices\n",
    "class_to_idx = dataset.class_to_idx\n",
    "selected_indices = [class_to_idx[c] for c in foods]\n",
    "\n",
    "def filter_dataset(ds):\n",
    "    indices = [i for i, (_, y) in enumerate(ds) if y in selected_indices]\n",
    "    return Subset(ds, indices)\n",
    "\n",
    "train_subset = filter_dataset(dataset)\n",
    "test_subset = filter_dataset(test_dataset)\n",
    "\n",
    "# Remap labels to 0–4\n",
    "class_map = {old: new for new, old in enumerate(selected_indices)}\n",
    "\n",
    "def remap_labels(batch):\n",
    "    images, labels = batch\n",
    "    labels = torch.tensor([class_map[l.item()] for l in labels])\n",
    "    return images, labels\n",
    "\n",
    "# ============================================================\n",
    "# 5. DATALOADERS\n",
    "# ============================================================\n",
    "\n",
    "train_loader_v1 = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "train_loader_v2 = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "\n",
    "# ============================================================\n",
    "# 6. MODEL SETUP (RESNET18)\n",
    "# ============================================================\n",
    "\n",
    "def create_model():\n",
    "    model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model.fc = nn.Linear(512, 5)\n",
    "    return model.to(device)\n",
    "\n",
    "# ============================================================\n",
    "# 7. TRAINING FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def train_model(model, train_loader, optimizer, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    acc_history = []\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = remap_labels((images, labels))\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        acc_history.append(acc)\n",
    "        loss_history.append(running_loss / len(train_loader))\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/10] Loss: {loss_history[-1]:.4f}, Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    return acc_history, loss_history\n",
    "\n",
    "# ============================================================\n",
    "# 8. VERSION 1 TRAINING (Adam, LR=0.0001, BS=32)\n",
    "# ============================================================\n",
    "\n",
    "model_v1 = create_model()\n",
    "optimizer_v1 = optim.Adam(model_v1.fc.parameters(), lr=0.0001)\n",
    "\n",
    "acc_v1, loss_v1 = train_model(model_v1, train_loader_v1)\n",
    "\n",
    "# ============================================================\n",
    "# 9. VERSION 2 TRAINING (Option B: Batch Size = 64)\n",
    "# ============================================================\n",
    "\n",
    "model_v2 = create_model()\n",
    "optimizer_v2 = optim.Adam(model_v2.fc.parameters(), lr=0.0001)\n",
    "\n",
    "acc_v2, loss_v2 = train_model(model_v2, train_loader_v2)\n",
    "\n",
    "# ============================================================\n",
    "# 10. TRAINING COMPARISON PLOT\n",
    "# ============================================================\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(acc_v1, label=\"Version 1 (BS=32)\")\n",
    "plt.plot(acc_v2, label=\"Version 2 (BS=64)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training Accuracy Comparison\")\n",
    "plt.legend()\n",
    "plt.savefig(\"training_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 11. EVALUATION + CONFUSION MATRIX\n",
    "# ============================================================\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = remap_labels((images, labels))\n",
    "            images = images.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    return np.array(y_true), np.array(y_pred)\n",
    "\n",
    "best_model = model_v2 if acc_v2[-1] > acc_v1[-1] else model_v1\n",
    "y_true, y_pred = evaluate(best_model)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=foods)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (Best Model)\")\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 12. SAMPLE PREDICTIONS (10 IMAGES)\n",
    "# ============================================================\n",
    "\n",
    "best_model.eval()\n",
    "samples = random.sample(range(len(test_subset)), 10)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, idx in enumerate(samples):\n",
    "    img, label = test_subset[idx]\n",
    "    img_input = img.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = best_model(img_input)\n",
    "        pred = output.argmax(1).item()\n",
    "\n",
    "    img = img.permute(1, 2, 0)\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"T: {foods[label]}\\nP: {foods[pred]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sample_predictions.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 13. RESULTS TABLE + ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n===== ACCURACY COMPARISON =====\")\n",
    "print(f\"Version 1 Final Accuracy: {acc_v1[-1]:.2f}%\")\n",
    "print(f\"Version 2 Final Accuracy: {acc_v2[-1]:.2f}%\")\n",
    "\n",
    "print(\"\\n===== ANALYSIS =====\")\n",
    "print(\"\"\"\n",
    "Version 2 performed better due to larger batch size (64),\n",
    "which provides more stable gradient estimates and smoother convergence.\n",
    "This improved generalization and final accuracy compared to Version 1.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef9f637-225d-4f2d-b3f6-16a5c217e747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
